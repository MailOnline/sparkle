machine:
  environment:
    PATH: ~/.local/bin:~/spark/bin:$PATH
  services:
  - docker

checkout:
  post:
  - git submodule update --recursive --init

dependencies:
  cache_directories:
  - "~/.stack"

  override:
  - mkdir -p ~/.local/bin
  - curl -L --retry 3 https://www.stackage.org/stack/linux-x86_64 | tar xz --wildcards --strip-components=1 -C ~/.local/bin '*/stack'
  - docker build -t sparkle .
  - stack --no-terminal --docker --docker-image sparkle build --only-snapshot --prefetch

test:
  override:
  - stack --no-terminal --docker --docker-image sparkle build --pedantic
  # Test that packaging at least one example works fine.
  - stack --no-terminal --docker --docker-image sparkle exec sparkle package sparkle-example-hello
  # XXX --packages flag should not be necessary. Workaround regression
  # in Spark 2.2 vs 2.1 in Nixpkgs.
  - stack --no-terminal --docker --docker-image sparkle exec -- spark-submit --master 'local[1]' --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.2,com.google.guava:guava:12.0 sparkle-example-hello.jar
